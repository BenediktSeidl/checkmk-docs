include::global_attr.adoc[]
= Cluster-Services überwachen
:revdate: draft
:title: Cluster-Services überwachen
:description: Eine Gruppe von vernetzten Hosts, die zusammenarbeiten, um die gleiche Aufgabe zu erledigen, wird als Cluster bezeichnet. Ein Cluster bietet einen oder mehrere Services nach außen an. Checkmk hilft Ihnen dabei, diese Cluster-Services zu überwachen.

[TIP]
.Related Articles:
====
link:wato_hosts.html[]

====


== Einleitung

COMMENT[TK: Die Relevanz bestimmter im Altkapitel enthaltener Informationen muss noch überprüft werden aus den Kapiteln: 2.2. 2. Define which services are clustered, 2.3. 3. Running the inventory, 2.5. Manually defined checks, 3. Clusters and host tags, 3.1. Clusters and Nagios configuration, 4. Caching]

Bei der Bereitstellung wichtiger und geschäftskritischer Services wie Datenbanken oder Websites für den elektronischen Handel (E-commerce) werden Sie sich kaum darauf verlassen, dass der Host, auf dem diese Services laufen, ein langes, stabiles und absturzfreies Leben führen wird. Stattdessen werden Sie den Ausfall eines Hosts einkalkulieren und dafür sorgen, dass andere Hosts bereitstehen, um bei einem Ausfall die Services unmittelbar zu übernehmen (Failover), so dass sich der Ausfall nach außen gar nicht bemerkbar macht.

=== Cluster, Knoten und Cluster-Services
Eine Gruppe von vernetzten Hosts, die zusammenarbeiten, um die gleiche Aufgabe zu erledigen, wird als Rechnerverbund oder Computer-Cluster oder kürzer und im folgenden nur noch als Cluster bezeichnet. Ein Cluster agiert nach außen als ein System und organisiert nach innen die Zusammenarbeit der Hosts, um die gemeinsame Aufgabe zu erfüllen.

Ein Cluster kann verschiedene Aufgaben übernehmen, zum Beispiel ein HPC-Cluster das Hochleistungsrechnen (high-performance computing), das unter anderem dann eingesetzt wird, wenn Berechnungen viel mehr Speicher benötigen als auf einem Computer verfügbar ist oder ein Programm mehrfach ausgeführt werden muss (normalerweise mit unterschiedlichen Eingabedaten). Falls das Cluster die Aufgabe hat, die Verfügbarkeit auf Hochverfügbarkeit (high availability) zu erhöhen, wird es auch als HA-Cluster bezeichnet.

Ein Cluster bietet einen oder mehrere Services nach außen an: die sogenannten Cluster-Services. In einem Cluster werden die Hosts, aus denen es besteht, als Knoten (nodes) bezeichnet. Zu einem bestimmten Zeitpunkt wird jeder Service von genau einem der Knoten bereitgestellt. Fällt ein Knoten des Clusters aus, werden alle Services, die für die Aufgabe des Clusters essentiell sind, auf einen der verbleibenden Knoten verschoben,

Um ein Failover transparent zu machen, stellen einige Cluster eine eigene Cluster-IP-Adresse zur Verfügung, die manchmal auch als virtuelle IP-Adresse bezeichnet wird. Die Cluster-IP-Adresse verweist auf den derzeit aktiven Knoten und steht  stellvertretend für das gesamte Cluster. Im Falle eines Failovers geht die IP-Adresse auf einen anderen, bisher passiven Knoten über, der dann zum aktiven Knoten wird. Der Client, der mit dem Cluster kommuniziert, braucht nicht umzuschalten. Er kann weiterhin die gleiche IP-Adresse verwenden.

Andere Cluster haben keine Cluster-IP-Adresse. In einem solchen Fall führt der Client eine Liste der IP-Adressen aller Knoten, die den Service bereitstellen könnten, und muss einen Failover im Cluster selbst erkennen. Ein prominentes Beispiel sind Oracle-Datenbank-Cluster in vielen ihrer Varianten.


=== Das Monitoring eines Clusters

{CMK} ist einer der Clients, der mit dem Cluster kommuniziert. In {CMK} können alle Knoten eines Clusters eingerichtet und überwacht werden -- unabhängig davon, wie die Cluster-Software intern den Status der einzelnen Knoten überprüft und, falls notwendig, einen Failover durchführt.

Die meisten Checks, die {CMK} auf den einzelnen Knoten eines Clusters ausführt, befassen sich mit den physischen Eigenschaften der Knoten, die unabhängig davon sind, ob der Host zu einem Cluster gehört oder nicht. Beispiele dafür sind CPU- und Speichernutzung, lokale Festplatten, physische Netzwerkschnittstellen usw. Für die Abbildung der Cluster-Funktion der Knoten in {CMK} ist es aber notwendig, diejenigen Services zu identifizieren, die die Aufgabe des Clusters definieren und gegebenenfalls auf einen anderen Knoten übertragen werden: die  Cluster-Services.

Nehmen wir an, dass {CMK} die Verfügbarkeit eines bestimmten Cluster-Services prüfen will. Auf welchem Knoten soll es den Service suchen? Wenn das Cluster eine Cluster-IP-Adresse hat, kann {CMK} sich mit dieser verbinden und wird den aktiven Knoten erreichen, auf dem der Service läuft. Ohne eine Cluster-IP-Adresse wird es komplizierter, da {CMK} von allen Knoten des Clusters Daten abrufen muss, um denjenigen zu finden, auf dem der Service läuft und der damit der aktive Knoten ist.

{CMK} hilft Ihnen dabei, die Cluster-Services zu überwachen. Was Sie tun müssen, ist:

. Cluster erstellen
. Cluster-Services auswählen
. Service-Erkennung für alle beteiligten Hosts durchführen

Wie Sie dabei vorgehen, wird im nächsten Kapitel anhand der folgenden Beispielkonfiguration beschrieben:

COMMENT[TK: Beispiel sollte am besten so gewählt werden, dass es auch für die überlappenden Cluster einfach abwandelbar ist. Zur Beispielkonfiguration gehört auch (fehlt aber noch), welche Cluster-Services ausgewählt werden sollen.]

* Cluster klump1 mit den zwei Knoten knot11 und knot12
* Cluster klump2 mit den drei Knoten knot21, knot22 und knot23

Anders als in diesem Beispiel ist es auch möglich, das derselbe Knoten in mehreren Clustern enthalten ist. Im letzten Kapitel erfahren Sie, wie Sie solche überlappende Cluster konfigurieren.


== Cluster und Cluster-Services einrichten

COMMENT[TK: Die folgenden Kapitel sind noch nicht ausformuliert. Es wird nur skizziert welche Informationen beschrieben werden sollen.]


=== Cluster erstellen

In {CMK} werden die Knoten und das Cluster selbst als Hosts erstellt (Cluster-Hosts und Knoten-Hosts), wobei es für einen Cluster-Host einen speziellen Host-Typen gibt. Der Cluster-Host ist ein logischer Host, der mit Cluster-IP-Adresse konfiguriert werden soll, wenn diese existiert. Cluster-Hosts können auf die gleiche Art und Weise konfiguriert werden wie "normale" Hosts, zum Beispiel mit [wato_hosts#Hostgruppen|Host-Gruppen] oder link:intro.html#hosttags[Host-Merkmalen].

Für alle beteiligten Hosts (damit sind stets der Cluster-Host und alle zugehörigen Knoten-Hosts gemeint), müssen die Datenquellen identisch konfiguriert werden, d.h. insbesondere dürfen nicht einige per Check_MK Agent und andere per SNMP konfiguriert sein.

Falls die Hosts in Ordner organisiert sind, vereinfacht es die Einrichtung (bei der Auswahl der Cluster-Services im nächsten Kapitel) wenn sich alle alle beteiligten Hosts im gleichen Ordner befinden.

Prozedur:

Voraussetzung: Alle 5 Knoten der beiden Cluster sind bereits als link:wato_hosts.html[Hosts] angelegt (per [.guihint]#WATO|Hosts|New host#).

. Erstes Cluster anlegen per [.guihint]#WATO|Hosts|New cluster|Create new cluster# mit Screenshot: Create new cluster page mit aufgeklappten Kategorien Basic settings, Network Address, Data sources
. Folgende Parameter featuren: [.guihint]#Hostname# (klump1), [.guihint]#Nodes#: knot11 und knot12 (Obacht: GUI-Handling bei Nodes-Auswahl tricky), [.guihint]#IPv4 Address#: Cluster-IP-Adresse (falls verfügbar), [.guihint]#Data Sources#: siehe oben
. Abschließen mit [.guihint]#Save & Finish#

Analog zweites Cluster klump2 anlegen.

In einem link:distributed_monitoring.html[verteilten Monitoring] müssen alle beteiligten Hosts derselben {CMK}-Instanz zugeordnet sein.


=== Cluster-Services auswählen

COMMENT[TK: Es fehlt noch, welche Cluster-Services bespielhaft ausgewählt werden sollen.]

{CMK} kann nicht wissen, welche der auf einem Knoten laufenden Services lokale und welche Cluster-Services sind: Einige Dateisysteme können lokal sein, andere sind möglicherweise nur auf dem aktiven Knoten gemountet. Ähnliches gilt für Prozesse: Während der NTP (Network Time Protocol) Daemon höchstwahrscheinlich auf allen Knoten läuft, wird eine bestimmte Datenbankinstanz nur auf dem aktiven Knoten verfügbar sein.

Statt {CMK} raten zu lassen, wählen Sie die Cluster-Services mit einer Regel aus.

Da die Regel für die Knoten gilt, auf denen die Services laufen, muss diese Regel für den Ordner erstellt werden, in dem sich die Knoten-Hosts befinden (d.h. _nicht_ der Ordner mit dem Cluster-Host, falls die Hosts in unterschiedlichen Ordnern organisiert sind).

Prozedur:

. [.guihint]#WATO|Hosts# > Cluster-Name anklicken > link:.guihint].html#Clustered Services[Create rule in folder# > Ordner mit den Knoten-Hosts auswählen > [.guihint]#New rule: Clustered Services# mit Screenshot: Create new cluster page mit aufgeklappter Kategorie Conditions
. [.guihint]#Services# markieren und in die Eingabefelder die Services eintragen, die als Cluster-Services dem Cluster zugeordnet werden sollen. Die Eingaben werden als link:regexes.html[reguläre Ausdrücke] interpretiert, zum Beispiel führt die Eingabe von  `Interface` dazu, dass alle Services ausgewählt werden, deren Namen mit Interface _beginnen_.
. Abschließen mit [.guihint]#Save#

Erfolgskontrolle, d.h. wie finde ich heraus, dass meine Service-Auswahl zum  gewollten Ergebnis geführt hat?
[.guihint]#WATO|Hosts# > Klicken Sie in der Host-Liste für den Cluster-Host auf ICON[icon_services.png] > [.guihint]#Services of host# page. Auf dieser Seite werden unter [.guihint]#Monitored services# alle Services aufgelistet, die dem Cluster zugewiesen sind.

Alle Services, die nicht als Cluster-Services definiert sind, werden von {CMK} als lokale Services behandelt.


//Let's make an example that defines the filesystems `/cdarchiv` and `/exchange` to be clustered:

//F+:main.mk
//clustered_services = [
// ( ALL_HOSTS, [ "fs_/cdarchiv", "fs_/exchange" ] )
//]
//F-:

//On the next discovers, if a new check with the description `fs_/cdarchiv` is found on a host *and* if that host is the node of a cluster, then the new check will be assigned to the cluster instead of the node.

//A few remarks about the example:
//LI:The services do not *have* to exist on each cluster.
////LI:If you are unsure about how services are correctly named, please look into the GUI of Nagios - check_mk uses the Nagios service descriptions.
//LI:Services on hosts which are not part of a cluster are never considered clustered. So you wouldn't need to worry about a filesystem `/cdarchiv` on a non-cluster host `abc123`.
//LI:The service names are regular expressions matching the *beginning* of the service description. So if want `fs_/test` to be clustered, but `fs_/test2` *not* to be clustered, you need to write`"fs_/test$"`.

//Let's now assume that the filesystem `/cdarchiv` is a clustered service only on `klump1`, but is a local service on all other clusters:

//F+:main.mk
//clustered_services = [
// ( ["knot11", "knot12"], [ "fs_/cdarchiv" ] ),
// ( ALL_HOSTS,            [ "fs_/exchange" ] )
//]
//F-:

//You can also use host tags. Please note, that `clustered_services` always refers to the *nodes*, not to the cluster hosts. The following example configures several services to be clustered on nodes with the tag `oracle`:

//F+:main.mk
//all_hosts = [
// "knot11|*oracle*",
// "knot12|*oracle*",
// "knot21",
// "knot22",
// "knot23",
//]

//clusters = {
// "klump1" : [ "knot11", "knot12" ],
// "klump2" : [ "knot21", "knot22", "knot23" ],
//}

//clustered_services = [
// ( ["*oracle*"], ALL_HOSTS, [ "fs_/ora/space123" ] ),
//]
//F-:


=== Service-Erkennung für alle beteiligten Hosts durchführen

Für alle beteiligten Hosts (Cluster- und Knoten-Hosts) muss zum Abschluss eine neue Service-Erkennung (discovery) durchgeführt werden, damit alle neu definierten Cluster-Services zuerst bei den Knoten entfernt und dann beim Cluster hinzugefügt werden.

Prozedur:

. link:.guihint].html#WATO[Hosts# > Alle beteiligten Hosts markieren > [.guihint]#Discovery|Bulk discovery# mit Screenshot: Bulk discovery
. Hinweis zu empfohlenen Optionen bei der link:wato_services.html#bulk_discovery[Serviceerkennung für viele Hosts]: Die erste Option [.guihint]#Add unmonitored services and new host labels# sollte zum gewünschten Ergebnis führen. Falls nicht, erneut versuchen mit dritter Option [.guihint]#Add unmonitored services and new host labels, remove vanished services#.
. [.guihint]#Start# > Ergebnis: "Result	Bulk discovery successful"

Erfolgskontrolle: [.guihint]#WATO|Hosts# > Klicken Sie in der Host-Liste für einen Knoten-Host auf ICON[icon_services.png] > [.guihint]#Services of host# page. Auf dieser Seite werden zuerst die [.guihint]#Monitored services# und danach (ganz unten auf der Seite) die [.guihint]#Monitored clustered services (located on cluster host)# aufgelistet, das heißt die Services, die von diesem Knoten dem Cluster zugewiesen sind.

COMMENT[TK: Der folgende Tipp gehört nicht hierhin, sondern in den Artikel, in dem es um das allgemeine Service-Handling geht, also z.B. nach: link:wato_services.html#discovery[Services eines Hosts in WATO]]

*Tipp:* Falls Sie auf einem Host einen Service vermissen, kann es daran liegen, dass der Service als Cluster-Service konfiguriert wurde und daher nicht in der ersten [.guihint]#Monitored services# Liste aufgeführt wird, sondern in der zweiten [.guihint]#Monitored clustered services (located on cluster host)# Liste.


//H2:Manually defined checks

//Some check types do not support inventory. You can assign such checks to clusters just as you would do for normal hosts in `checks`. Please note:

//LI:`clustered_services` has no effect on manually configured checks or already inventorized checks.
//LI:Clustered services have to be assigned to the *cluster host* in `checks`

//When using host tags within `checks` you can use the one of the following keywords instead of an explicit host list:

//<table>
//<tr><td class=tt>PHYSICAL_HOSTS</td><td>All non-cluster hosts</td></tr>
//<tr><td class=tt>CLUSTER_HOSTS</td><td>All cluster hosts (not there nodes, just the clusters)</td></tr>
//<tr><td class=tt>ALL_HOSTS</td><td>All physical and cluster hosts</td></tr>
//</table>

//The following example will check for `/usr/sbin/ntpd` on all physical hosts with the tag `linux`:

//F+:main.mk
//checks = [
//  ( ["linux"], PHYSICAL_HOSTS, "ps", "NTPD", ( "/usr/sbin/ntpd",1,1,1,1 ) ),
//]
//F-:

//Now let's configure a check for a process with `_K15` in its name on each cluster:

//F+:main.mk
//checks = [
//  ( CLUSTER_HOSTS, "ps", "K15", ( ".*_K15", 1, 1, 1, 1 ) ),
//]
//F-:


//H1:Clusters and host tags

//Not only physical hosts but also clusters can have host tags. They are defined within `clusters`:

//F+:main.mk
//clusters = {
// "klump1|*oracle*" : [ "knot11", "knot12" ],
// "klump2"        : [ "knot21", "knot22", "knot23" ],
//}
//F-:

//Host tags of clusters can be used within `checks` and most other places where host tags are allowed. They do *not* make sense within `clustered_services`, since that variable is never evaluated for cluster hosts but only for physical nodes. The following examples alters the upper example such that only on ORACLE clusters the `K15` process should be running:

//F+:main.mk
//checks = [
//  ( ["*oracle*"], CLUSTER_HOSTS, "ps", "K15", ( ".*_K15", 1, 1, 1, 1 ) ),
//]
//F-:

//H2:Clusters and Nagios configuration
//From the point of view of Nagios clusters are ordinary hosts. They can be members of host groups, have contact groups, notification periods and so on. All check_mk variables influencing the Nagios configuration will also have effect on cluster hosts.

//Please make sure that you set the tags accordingly in `all_hosts` and `clusters`. Let's assume that you have some ORACLE clusters and you want their physical nodes as well as the clusters themselves both to be in a host group `oraclehosts`:

//F+:main.mk
//clusters = {
// "klump1|*oracle*" : [ "knot11", "knot12" ],  # ORACLE cluster
// "klump2"        : [ "knot21", "knot22", "knot23" ],
//}

//all_hosts = [
// "knot11|*oracle*",  # physical node of ORACLE cluster
// "knot12|*oracle*",  # physical node of ORACLE cluster
// "knot21",
// "knot22",
// "knot23",
//]

//host_groups = [
// ( "oraclehosts", ["*oracle*"], ALL_HOSTS )
//]
//F-:


//H1:Caching

//Are you worried about performance? If you monitor the cluster `klump1` and its nodes `knot11` and `knot12`, wouldn't check_mk retrieve the data from `knot11` and `knot12` twice each check cycle?

//In order to avoid that, check_mk makes use of cache files, if they are recent enough. If you interested, how this works, please continue reading link:cache.html[here].



== Überlappende Cluster

COMMENT[TK: Hier fehlt noch das am 27.08. in Slack > consulting von Alex Wilms beschriebene Beispiel mit einem MSSQL Cluster mit 2 Knoten bei 100%iger Überlappung.]

Es ist möglich, dass mehrere Cluster einen oder auch mehrere Knoten gemeinsam nutzen. Man spricht dann von überlappenden Clustern.

Für überlappende Cluster ist es nicht ausreichend, die Cluster-Services auszuwählen. Zusätzlich müssen diese Services auf dem von mehreren Clustern genutzten Knoten auch noch dem richtigen Cluster zugeordnet werden.

Diese Auswahl der Services und die Zuordnung zu einem Cluster erfolgt in {CMK} mit einer eigenen Regel:

[.guihint]#WATO|Host & Service Parameters|Monitoring Configuration|Various# > [.guihint]#Clustered services for overlapping clusters#

Falls mehrere Regeln einen Cluster-Service definieren, hat die spezifischere Regel [.guihint]#Clustered services for overlapping clusters# mit der expliziten Zuordnung zu einem bestimmten Cluster Vorrang vor der allgemeineren Regel [.guihint]#Clustered Services#.


//As of version 1.1.4 Checkmk allows clusters to overlap. That means that you have two different clusters sharing one or more nodes. Such as notion might sound strange at the first sight, but believe me: there are some weird but experienced users out there who know what they want and who sought such a feature for a long time. And we need to keep those weird and experienced users happy, since they are sending pretty good patches and bug reports and - even more important - implement features for us that we strongly want in *their* Nagios addons...

//So, if you define overlapping clusters just one problem arises: If the discovery finds a clustered check on one of the shared nodes, then which cluster should it be assigned to? Let's make an example:

//F+:main.mk
//clusters = {
// "north" : [ "northeast", "*northwest*" ],
// "west"  : [ "southwest", "*northwest*" ],
//}

//# old-style: bad here
//clustered_services = [
//  ( ALL_HOSTS, [ "fs_/foo" ] ),
//]
//F-:

//Now: if the inventory finds a service called `fs_/foo` on `northwest`, which cluster should it be assigned to? Checkmk cannot know and will randomly choose one of the clusters. But: with the new config variable `clustered_services_of`, you have a solution for that case:

//F+:
//# better here: make explicit assignment
//clustered_services_of["west"] = [
//  ( ALL_HOSTS, [ "fs_/foo" ] ),
//]
//F-:

//Now the services beginning with `fs_/foo` will - if found - be assigned to the cluster `west`.

//It is completely legal to use both `clustered_services` and `clustered_services_of` in parallel. Just keep in mind, that `clustered_services_of` has precedence. If a service is matching both configurations, the explicit assignment to a specific cluster overrides the unspecific `clustered_services`.
